{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2018 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Converts PASCAL VOC 2012 data to TFRecord file format with Example protos.\n",
    "\n",
    "PASCAL VOC 2012 dataset is expected to have the following directory structure:\n",
    "\n",
    "  + pascal_voc_seg\n",
    "    - build_data.py\n",
    "    - build_voc2012_data.py (current working directory).\n",
    "    + VOCdevkit\n",
    "      + VOC2012\n",
    "        + JPEGImages\n",
    "        + SegmentationClass\n",
    "        + ImageSets\n",
    "          + Segmentation\n",
    "    + tfrecord\n",
    "\n",
    "Image folder:\n",
    "  ./VOCdevkit/VOC2012/JPEGImages\n",
    "\n",
    "Semantic segmentation annotations:\n",
    "  ./VOCdevkit/VOC2012/SegmentationClass\n",
    "\n",
    "list folder:\n",
    "  ./VOCdevkit/VOC2012/ImageSets/Segmentation\n",
    "\n",
    "This script converts data into sharded data files and save at tfrecord folder.\n",
    "\n",
    "The Example proto contains the following fields:\n",
    "\n",
    "  image/encoded: encoded image content.\n",
    "  image/filename: image filename.\n",
    "  image/format: image file format.\n",
    "  image/height: image height.\n",
    "  image/width: image width.\n",
    "  image/channels: image channels.\n",
    "  image/segmentation/class/encoded: encoded semantic segmentation content.\n",
    "  image/segmentation/class/format: semantic segmentation file format.\n",
    "\"\"\"\n",
    "import math\n",
    "import os.path\n",
    "import sys\n",
    "import build_data\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('image_folder',\n",
    "                           '.\\Edges\\JPEGImages',\n",
    "                           'Folder containing images.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'semantic_segmentation_folder',\n",
    "    '.\\Edges\\SegmentationClass',\n",
    "    'Folder containing semantic segmentation annotations.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'list_folder',\n",
    "    '.\\Edges\\ImageSets',\n",
    "    'Folder containing lists for training and validation')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'output_dir',\n",
    "    './tfrecord',\n",
    "    'Path to save converted SSTable of TensorFlow examples.')\n",
    "\n",
    "\n",
    "_NUM_SHARDS = 4\n",
    "\n",
    "print(\"hello\")\n",
    "def _convert_dataset(dataset_split):\n",
    "  \"\"\"Converts the specified dataset split to TFRecord format.\n",
    "\n",
    "  Args:\n",
    "    dataset_split: The dataset split (e.g., train, test).\n",
    "\n",
    "  Raises:\n",
    "    RuntimeError: If loaded image and label have different shape.\n",
    "  \"\"\"\n",
    "    print(\"hello2\")\n",
    "    dataset = os.path.basename(dataset_split)[:-4]\n",
    "    sys.stdout.write('Processing ' + dataset)\n",
    "    filenames = [x.strip('\\n') for x in open(dataset_split, 'r')]\n",
    "    num_images = len(filenames)\n",
    "    num_per_shard = int(math.ceil(num_images / float(_NUM_SHARDS)))\n",
    "    print(\"hello3\")\n",
    "    image_reader = build_data.ImageReader('jpeg', channels=3)\n",
    "    print(\"hello4\")\n",
    "    label_reader = build_data.ImageReader('jpg', channels=1)\n",
    "    print(\"hello5\")\n",
    "    for shard_id in range(_NUM_SHARDS):\n",
    "        output_filename = os.path.join(\n",
    "            FLAGS.output_dir,\n",
    "            '%s-%05d-of-%05d.tfrecord' % (dataset, shard_id, _NUM_SHARDS))\n",
    "        with tf.python_io.TFRecordWriter(output_filename) as tfrecord_writer:\n",
    "            start_idx = shard_id * num_per_shard\n",
    "            end_idx = min((shard_id + 1) * num_per_shard, num_images)\n",
    "        for i in range(start_idx, end_idx):\n",
    "            sys.stdout.write('\\r>> Converting image %d/%d shard %d' % (\n",
    "                i + 1, len(filenames), shard_id))\n",
    "            sys.stdout.flush()\n",
    "            # Read the image.\n",
    "            image_filename = os.path.join(\n",
    "                FLAGS.image_folder, filenames[i] + '.' + FLAGS.image_format)\n",
    "            image_data = tf.gfile.FastGFile(image_filename, 'rb').read()\n",
    "            height, width = image_reader.read_image_dims(image_data)\n",
    "            print(\"python\")\n",
    "            # Read the semantic segmentation annotation.\n",
    "            seg_filename = os.path.join(\n",
    "                FLAGS.semantic_segmentation_folder,\n",
    "                filenames[i] + '.' + FLAGS.label_format)\n",
    "            seg_data = tf.gfile.FastGFile(seg_filename, 'rb').read()\n",
    "            seg_height, seg_width = label_reader.read_image_dims(seg_data)\n",
    "            if height != seg_height or width != seg_width:\n",
    "                raise RuntimeError('Shape mismatched between image and label.')\n",
    "            # Convert to tf example.\n",
    "            example = build_data.image_seg_to_tfexample(\n",
    "                image_data, filenames[i], height, width, seg_data)\n",
    "            tfrecord_writer.write(example.SerializeToString())\n",
    "        sys.stdout.write('\\n')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "    dataset_splits = tf.gfile.Glob(os.path.join(FLAGS.list_folder, '*.txt'))\n",
    "    for dataset_split in dataset_splits:\n",
    "        _convert_dataset(dataset_split)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
